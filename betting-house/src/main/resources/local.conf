akka {

  actor {
    provider = cluster

     serialization-bindings {
      "example.betting.CborSerializable" = jackson-cbor
    }
  }

  remote {
    artery {
      canonical.hostname = "127.0.0.1"
      canonical.port = 25525
    }
  }

  cluster {
    seed-nodes = [
      "akka://betting-house@127.0.0.1:25525"]
    downing-provider-class = "akka.cluster.sbr.SplitBrainResolverProvider"
  }

  http.server.preview.enable-http2 = on

  # use JDBC plugin to store both snapshots and the events of the persistent actors
  persistence {
    journal.plugin = "jdbc-journal"
    auto-start-journals = ["jdbc-journal"]

    snapshot-store.plugin = "jdbc-snapshot-store"
    auto-start-snapshot-stores = ["jdbc-snapshot-store"]
  }
}
akka.projection.jdbc {
  # blocking-jdbc-dispatche is the default dispatcher from akka-projection/reference.conf
  # we configure it here
  blocking-jdbc-dispatcher.thread-pool-executor.fixed-pool-size = 8 
  # we must choose one `dialect` of: mysql-dialect, postgres-dialect, mssql-dialect, oracle-dialect or h2-dialect (testing)
  dialect = "postgres-dialect"

}


services {
  host = "0.0.0.0"
  bet.port = 9000
  wallet.port = 9001
  market.port = 9002
  bet-projection.port = 9003
}

kafka {
  bet-projection.topic = "bet-projection"
}

kafka-connection-settings {
  # This and other connection settings may have to be changed depending on environment.
  bootstrap.servers = "127.0.0.1:9092"
}

  

akka.kafka.producer {
  # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
  kafka-clients = ${kafka-connection-settings}
}


# These settings configure the database connection for ScalikeJDBC and the akka-persistence-jdbc plugin
jdbc-connection-settings {
  driver = "org.postgresql.Driver"
  # the following properties must be filled with the production values
  # they can be set using -D arguments, eg: -jdbc-connection-settings.user=the-production-user
  url = "jdbc:postgresql://127.0.0.1:5432/betting"  
  user = betting 
  password = betting


  # the following properties are used to configure the
  # Hikari connection pool used on the read-side (akka-projections)
  connection-pool {
    # How many connections should be available to from the pool?
    # it's recommended to use the same value used by the blocking-jdbc-dispatcher (see above)
    max-pool-size = ${akka.projection.jdbc.blocking-jdbc-dispatcher.thread-pool-executor.fixed-pool-size}

    # How long should we wait (in millis) before it times out?
    # In a normal scenario, we should always be able to get a connection
    # If we got a thread from the blocking-jdbc-dispatcher, we should be able to get a connection.
    # If for some reason the pool can't provide a connection, it's better to let it crash and liberate the current thread.
    # Hence the low timout (note, 250 is lowest value hikari accepts)
    timeout = 250ms
  }
}


akka-persistence-jdbc {
  shared-databases {
    default {
      # the slick profile must be compatible with the configured jdbc-connection-settings.driver
      # possible choices are:
      #  - slick.jdbc.PostgresProfile$
      #  - slick.jdbc.MySQLProfile$
      #  - slick.jdbc.H2Profile$
      #  - slick.jdbc.SQLServerProfile$
      #  - slick.jdbc.OracleProfile$
      profile = "slick.jdbc.PostgresProfile$"
      db {
        host = "localhost"
        url = ${jdbc-connection-settings.url}
        user = ${jdbc-connection-settings.user}
        password = ${jdbc-connection-settings.password}
        driver = ${jdbc-connection-settings.driver}
        numThreads = 5
        maxConnections = 5
        minConnections = 1
      }
    }
  }
}

jdbc-journal {
  use-shared-db = "default"
}

# the akka-persistence-snapshot-store in use
jdbc-snapshot-store {
  use-shared-db = "default"
}

jdbc-read-journal {
  use-shared-db = "default"
}